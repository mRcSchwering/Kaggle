---
title: "Keine Panik auf der Titanic"
author: "Marc Schwering"
output:
  html_document:
    number_sections: true
    toc: true
    toc_depth: 2
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
---







# Introduction

This is my first Kaggle script so don't go too hard on me.
I used some machine learning in the past but only to solve biological problems,
so this is new.

While analyzing the dataset I will go through **Data Preparation**, 
**Modeling**, and **Prediction**.
*Data Preparation* means I look at the data quality, extract features,
explore these features, and handle missing values.
During *Modeling* the data is shaped for the model class, a form of feature 
selection is performed, and models are fit.
Then the models are analyzed.
Finally, the best model is used to make a *Prediction* for the test dataset.

This sounds straight forward but usually it is not.
It might happen that I go back and forth bewteen consecutive steps.

**Linear Discriminant Analysis**

I have looked into some scripts for the Titanic set.
A lot of people use random forest predictors.
I have seen nobody using linear discriminant analysis (LDA) yet which would be
my first thought.
In the modelling part I will try out a LDA and some of its cousins.

**Loading Data**

```{r, message=FALSE, warning=FALSE, results='hide'}
library(data.table) # database-like tables
library(ggplot2) # general plots
library(lattice) # also for plots
library(mice) # for imputation
library(klaR) # general functions for classification
library(sda) # LDA with special shrinkage method
library(crossval) # for cross validation
```

Let's load the data.
As you can see I belong to the `data.table` people.

```{r}
test <- read.csv("../input/test.csv")
train <- read.csv("../input/train.csv")
test <- data.table(test)
train <- data.table(train)
str(train)
str(test)
```

Some classes should be adjusted.

```{r, message=FALSE, warning=FALSE, results='hide'}
train[, Name := as.character(Name)]
train[, Ticket := as.character(Ticket)]
train[, Cabin := as.character(Cabin)]
train[, Survived := as.factor(Survived)]
train[, Pclass := as.factor(Pclass)]

test[, Name := as.character(Name)]
test[, Ticket := as.character(Ticket)]
test[, Cabin := as.character(Cabin)]
test[, Pclass := as.factor(Pclass)]
```








***







# Data Preparation

## Data Quality

Here, I basically go through the data and see if there is something
important like missing values or weird values.
I don't really look at distributions or correlations yet.
This is done in a later section.
To keep it short I will only show the stuff that is interesting in some way.
For a lot of these features I just did `table` or `summary` to confirm that
they look fine.

### Age

This is the first feature where I found missing values.

```{r}
summary(train$Age)
summary(test$Age)
```

I guess this is an impotant feature, so probably we have to infer
something here.
The age range seems reasonable:
from 2 months to 80 years old.


### Fare

```{r}
summary(train$Fare)
summary(test$Fare)
```

There is one $NA$ *Fare* in the test set.

```{r}
test[is.na(Fare), ]
```

Also, in both *test* and *train* there are some wildly high values of 512.3.
What's up with these?

```{r}
train[Fare > 512, ]
test[Fare > 512, ]
```

And there were free rides:

```{r}
train[Fare == 0, ]
test[Fare == 0, ]
```

The cases with `Fare == 0` also have a lot of missing values for *Age*.
I wonder whether `0` also denotes to a missing value for *Fare*.

### Cabin

```{r}
head(train$Cabin)
head(test$Cabin)
table(train$Cabin == "")
table(test$Cabin == "")
```

This looks bad.
Most are empty.

### Embarked

```{r}
table(train$Embarked)
table(test$Embarked)
train[Embarked == "", ]
```

In the training set there are 2 empty *Embarked* entries.
Both survived, maybe they didn't embark.

### Summary

+ *Age*: many $NA$ in test and train
+ *Fare*: 1 $NA$ in test, several 0's
+ *Cabin*: many empty strings in test and train
+ *Embarked*: 2 empty strings in train








## Feature Extraction

In general one could use some of these features already as they are.
Now I see if I can extract some more features.
This is quite exploratory.
I go through the training set and see what I can do.

### Names

I am starting with the *Names* column.
Obviously one can extract *Surnames* and *Titles* from the names.
The idea for the following code is taken from `mrisdal`'s Titanic kernel.
Titles and surnames are extracted from the *Names* column.
To reduce the number of titles a label *Rare Title* is created. 
It marks all titles that did not appear that often.

**Titles**

```{r}
train$Title <- gsub('(.*, )|(\\..*)', '', train$Name)
table(train$Title)
```

```{r, message=FALSE, results='hide'}
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
train[Title == "Mlle", Title := "Miss"]
train[Title == "Ms", Title := "Miss"]
train[Title == "Mme", Title := "Mrs"]
train[Title %in% rare_title, Title := "Rare Title"]
```

```{r}
table(train$Title, train$Sex)
```


**Surnames**

The idea for this part is also form `mrisdal`.

```{r}
train$Surname <- vapply(
  train$Name, 
  function(x) strsplit(x, "[,. ]")[[1]][1],
  character(1)
)
length(unique(train$Surname))
any(train$Surname == "")
```

**Surname Count**

I thought it would also be useful to have the number of people with identical
surnames aboard as a feature.
This might help later on when identifying families.

```{r}
counts <- table(train$Surname)
train$SNCount <- vapply(
  train$Surname, 
  function(sn) counts[names(counts) == sn],
  integer(1)
)
table(train$SNCount)
```

### Age

One important factor for survival is definitely the age.
As far as I know women and children were the first to board the rescue boats.
So, there should be a natural separation in the *Age* feature at 18.
I will extract this as a binary feature.

```{r}
train$isChild <- as.integer(train$Age < 18)
table(train$isChild)
```

### Families

Families probably stayed together.
So knowning the families would be good for prediction.
Using cabin information, Sibling/Spouses and Parent/Children, and the names
one could try to link family members.
For now I will just extract the general family size.

```{r}
train$FMembers <- train$SibSp + train$Parch + 1
table(train$FMembers)
```

### Ticket Text

The tickets are not only numbers.

```{r}
txt <- toupper(gsub("[0-9\\. /]", "", train$Ticket))
table(txt)
```

This seems to tell me the embarkment as well.
But this factor has to many levels in my opinion.
I will keep the most abundant levels and try to allocate the others
by similarity (that's quite subjective).
For the ones I don't know how to allocate I will create a label *other*.

```{r}
table(txt)[table(txt) > 10]
txt[txt == "AS"] <- "A"
txt[txt %in% c("C", "CASOTON")] <- "CA"
txt[txt %in% c("PC", "PPP", "PP")] <- "PC"
txt[txt %in% c("SC", "SCA")] <- "SCPARIS"
txt[txt %in% c("SOTONOQ", "STONO")] <- "SOTONO"
txt[!(txt %in% c("", "SOTONO", "SCPARIS", "PC", "CA"))] <- "other"
train$TicketText <- txt
table(train$TicketText)
```


### Cabins

The Cabin feature is very sparse.
However, for those that have values, we can extract the deck symbol and the 
number of cabins listed on the ticket.

**Deck** 

The highest deck should be *A*, the one below *B*, and so on.
The first character in the *Cabin* number is the deck.

```{r, results='hide'}
train$Deck <- vapply(
  train$Cabin, 
  function(x) strsplit(x, "")[[1]][1],
  character(1)
)
train[is.na(Deck), Deck := ""]
```

```{r}
table(train$Deck)
```

**Number of Cabins**

In some cases several cabins are listed.
Maybe that will be important.

```{r}
train$nCabins <- vapply(
  train$Cabin, 
  function(x) length(strsplit(x, " ")[[1]]),
  integer(1)
)
table(train$nCabins)
```

For the people who do not have a cabin I will also create a binary feature.

```{r}
train$hasCabin <- train$nCabins > 0
```








## Feature Exploration

In this section I will look at feature distributions and correlations.
This information is useful when constructing the final features for the model.

As said before I want to use linear discriminant analyses and related 
models.
It is known how these behave to certain data structures.
Highly correlated features for example can produce unstable coefficient
estimates.
Or differing covariance matrices among target classes (i.e. *survived*, 
*not survived*) violate the shared covariance assumption of the regular
LDA.
In general I will explore different combination of features in the **Modeling**
section anyway. 
But it is good to know the features in order to explain why certain model 
perform better than others.

Another thing is, that I might need to adjust some features.
A regular LDA for example assumes Gauss distributed features.
So, sometimes it makes sense to use transformations of a feature instead of
the raw feature (i.e. *basis expansion*).

Again, this is not a straight forward process.
I might extract some more features along the way.
Usually, I would go through each feature and look for correlation to 
(almost) every other feature.
To keep it short I will only print the inetresting plots and give a summary at
the end.


### Numeric Features Overview

At first I like to look at all numeric features, their correlation among each
others and their influence on the target variable.
A scatter plot matrix (SPLOM) is good for that.
In the following scatter plot matrix blue indicates *survived*.

```{r, fig.height = 10, fig.width = 10}
# color palette for Survived label
pal <- c("red", "blue")

# pearson corelation coefficients for SPLOM 
panel.cor <- function(x, y, digits = 2, cex.cor, ...) {
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  m <- cbind(x, y)
  m <- m[complete.cases(m), ]
  r <- cor(m[, 1], m[, 2])
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste("r= ", txt, sep = "")
  text(0.5, 0.5, txt)
}

# SPLOM
pairs(
  train[, .(Age, Fare, SibSp, Parch, FMembers, SNCount, nCabins)], 
  col = pal[train$Survived], 
  pch = 20,
  cex = 0.5,
  lower.panel = panel.cor
)
```

For discrete values one should be careful with the interpretation of these 
scatter plots. These few points that can be seen in distinct places are in 
reality many points plotted on top of each other.
The pearson correlation coefficients are still useful though.

For obvious reasons there is a high correlation between *SibSp* and *FMembers*, 
and *Parch* and *FMembers* (created from each other).
There is also a high correlation between *FMembers* and *SNCount*.
The correlation of *SNCount* to either *SibSp* or *Parch* is moderately high.

The remaining feature pairs do not show high correlations.

### Age

Let's see if the age has a substantial effect on survival chances.

I will plot densities for such comparisons.
They integrate to 1 which means I can nicely compare distributions of
2 features with different total counts.
Second, they use a kernel for local smoothing.
This way I only see the local trend.

```{r, warning=FALSE}
ggplot(train, aes(x = Age, fill = Survived)) +
  geom_density(alpha = .5) +
  theme_classic()
```

For both survivors and non-survivors the age distribution looks very similar.
There seems to be just one clear trend change between age 0 and 20.
This is probably because children boarded first.

However, from this plot I can't say whether this separation is really at the 
age of 18.
I can look at the proportions of survivors and non-survivors in 2 age groups
when setting the separation at different ages.

```{r}
dt <- train[!is.na(train$Age), 
            .(isU12 = Age < 12, isU14 = Age < 14,
              isU16 = Age < 16, isU18 = Age < 18,
              isU20 = Age < 20, isU22 = Age < 22,
              Survived)]
dt <- dt[, 
   .(isU12 = sum(isU12) / length(isU12), isU14 = sum(isU14) / length(isU14),
     isU16 = sum(isU16) / length(isU16), isU18 = sum(isU18) / length(isU18),
     isU20 = sum(isU20) / length(isU20), isU22 = sum(isU22) / length(isU22)), 
   by = Survived]
dt <- melt(dt, measure.vars = 2:7, variable.name = "Distinction",
           value.name = "People")
f <- function(x) { x[2] / x[1] }
dt <- dt[, .(Proportion = f(People)), by = Distinction]
ggplot(dt, aes(x = Distinction, y = Proportion, fill = Proportion)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic()
```

According to this plot, 18 would not be a good age to group children and adults.
I should rather use age 14.

```{r}
train$isU14 <- train$Age < 14
mosaicplot(table(train[, .(isU14, Survived)]), shade = TRUE)
```

The mosaic plot visualizes the contingency table of 2 factors as rectangles.
The color here shows the residuals of a model which assumes independence of both
factors.
So, the more colorful the rectangles, the less they can be explained by a 
independence model.
Here, this means feature *isU14* seems to explain the variability in *Survived*
to some degree.

### Families

**SibSp**

To visualize the distribution of discrete features I will use bar plots.

```{r}
ggplot(train, aes(x = SibSp, fill = Survived)) +
  geom_bar(position = "dodge") + 
  theme_classic()
```

Both classes (*survivor*/ *non-survivor*) show similar trends but the 
proportions seem to differ.
This is easier to see if I use a mosaic plot.

```{r}
mosaicplot(table(train[, .(SibSp, Survived)]), shade = TRUE)
```

It seems that large families in general had lower survival chances.
Passangers with 1 spouse/sibling had the highest survival chances.
But then people with zero spouses/sibling had lower survival chances 
again.

Maybe families in general had higher survival chances because there were 
children involved.
But then for the larger families it was harder to get every one together in the
chaos and that's why they again have lower survival chances.
(My theory for this...)

A linear separator would not be able to distinguish drop at 0 again.
I could engineer a metric like this:

```{r}
f <- function(x) { (1 - x)^2 }
mosaicplot(table(f(train$SibSp), train$Survived), shade = TRUE)
```

However, I have weirdly high values now.
Knowing that this affects the LDA fit a lot, I rather create a binary feature
to only capture $SibSp = 1$.

```{r}
train$SibSpIs1 <- train$SibSp == 1
mosaicplot(table(train[, .(SibSpIs1, Survived)]), shade = TRUE)
```


**Parch, FMembers, SNCount**

To make it short: I have seen similar trends in the family related features.
I always extracted the cases with highest survival rate as a binary feature.

```{r}
train$ParchIs1 <- train$Parch == 1
train$smallFamily <- train$FMembers > 1 & train$FMembers < 5
train$SNCountIs2 <- train$SNCount == 2
```

### Fare

This feature can be spread out better by a log transformation.
The log10 seems natural for money.

```{r, warning=FALSE}
ggplot(train, aes(x = Fare, fill = Survived)) +
  geom_density(alpha = .5) +
  scale_x_continuous(trans = "log10") +
  theme_classic()
```

It looks like survival chances were higher if you had an expensive ticket.
The capitalism is strong with this one.

```{r}
train$lFare <- log10(train$Fare + 1)
```


### Pclass

```{r}
mosaicplot(table(train[, .(Pclass, Survived)]), shade = TRUE)
```

This feature looks useful.
Higher classes had better survial chances.

### Ticket Text

```{r, fig.width=10}
mosaicplot(table(train[, .(TicketText, Survived)]), shade = TRUE)
```

The *PC* label seems to be a useful information.
I will make a feature for this.

```{r}
train$isPC <- train$TicketText == "PC"
```


### Deck

```{r, fig.width=10}
mosaicplot(table(train[, .(Deck, Survived)]), shade = TRUE)
```

Having no deck seems to be an indicator for low survival chances.

```{r}
train$noDeck <- train$Deck == ""
```

### Cabins

I did not see a trend in the number of cabins, only that having no cabin
is a bad omen.

```{r}
mosaicplot(table(train[, .(Survived, hasCabin)]), shade = TRUE)
```

### Embarked

Interestingly, people embarking from Cherbourg had higher survival chances.

```{r}
mosaicplot(table(train[, .(Embarked, Survived)]), shade = TRUE)
train$fromC <- train$Embarked == "C"
```

### Sex

I think this one is obvious.

```{r}
mosaicplot(table(train[, .(Sex, Survived)]), shade = TRUE)
```

### Title

```{r, fig.height=8, fig.width=8}
mosaicplot(table(train[, .(Title, Survived)]), shade = TRUE)
```

Well, needless to say the female titles had higher survival chances.
The interesting thing here is that *Master* and *Rare Title* have different 
survival chances than *Mr*.

```{r}
mosaicplot(table(train[Title %in% c("Rare Title", "Mr", "Master"), 
                   .(Title, Survived)]), shade = TRUE)
train$isMaster <- train$Title == "Master"
```


### Summary

**Among Features**

+ *FMembers* is highly correlated to *SibSp*, *Parch*, and *SNCount*
+ *SNCount* is moderately correlated to *SibSp* and *Parch*
+ *SibSp* and *Parch* is barely correlated
+ binary *Family* features are correlated among each other
+ *Fare* correlates with *Pclass*
+ *Embarked* is correlated with *TicketText*
+ *isPC* correlates with *Fare*
+ *nCabins* is highly correlated with *Deck*
+ *noDeck* correlates with *Fare*
+ *fromC* is correlated to *hasCabin*
+ *Title* is correlated to *Sex*

**To Target**

+ *Age*: for $Age \geq 14$ similar distributions among classes; for $Age \lt 14$
  more survivors
+ Families as represented by *SibSp*, *Parch*, *FMembers*, *SNCount*: large
  families have lower survival chances
+ *Fare*: higher fares have higher survival chances
+ *Pclass*: higher passanger classes have higher survival chances
+ *isPC*: $TicketText = PC$ means higher survival chances
+ *hasCabin*: having no cabin means lower survival chances
+ *fromC*: people from Cherbourg had higher survival chances
+ *Sex*: females had higher survival chances
+ *isMaster*: higher survival chance with title *Master*






## Missing Values

### Fare

There was 1 $NA$ for *Fare* in the test set.
Since this is just 1 value I think it is reasonable to set it to the median.

```{r, results='hide'}
test[is.na(Fare), Fare := median(c(test$Fare, train$Fare), na.rm = TRUE)]
```

### Embarked

In the train set there were 2 empty strings.
I saw many people label it with *C* because of the high fare (80) of these
passanger tickets.
Below is a violin plot that shows *Fare* densities for the *Embarked* variable.

```{r, warning=FALSE}
ggplot(train[!Embarked == ""], aes(x = Embarked, y = Fare)) +
  geom_violin(fill = "gray") +
  geom_boxplot(alpha = .5, varwidth = TRUE) +
  geom_hline(yintercept = 80, color = "red", linetype = 2) +
  scale_y_continuous(trans = "log10") +
  theme_classic()
```

The y-axis is log transformed to see the spread of *Fare* better.
The red line is drawn for $Fare = 80$.
Clearly, it seems unlikely that the passangers embarked in *Q*.
*C* seems slightly more likely than *S* according to the densities.
However, you can also see the prior probabilities of *Embarked*.
With `varwidth = TRUE` the boxplot widths are proportional to the square roots 
of the groups counts.

```{r}
prop.table(table(as.character(train[!Embarked == "", Embarked])))
```

Taking this into account I would rather set these two values to *S*

```{r, results='hide'}
train[Embarked == "", Embarked := "S"]
```

### Age

There were many $NA$s in *Age* and probably this is an important variable.
At least it is important to know whether or not a passanger was a child.
In other kernels I saw people using the `mice` package.
I didn't know this one before but it is also recommended in several forums.

It does multiple imputations using chained equations.
I'm not so familiar with imputation but there are two general ways to do 
imputation.
One is to impute variables one at a time. 
The other (Joint Modeling) is do impute these variables simultaneously.
This package does the former one.
As the name says it does this multiple times (by default 5 times).
This assures that the uncertainty of the data that is imputed is kept.

We will do this using a subset of useful variables.
We will also use both datasets for the imputation.

```{r, results='hide', message=FALSE}
full <- rbind(
  train[, .(Age, Pclass, Sex, lFare, Parch, SibSp)],
  test[, .(Age, Pclass, Sex, lFare = log(Fare + 1), Parch, SibSp)]
)
imp <- mice(full, seed = 42)
```
```{r}
imp
```

The summary tells us that 263 values for *Age* were imputed from *Pclass*, 
*Sex*, *lFare*, *Parch*, and *SibSp*.
The method used was predictive mean matching.
5 datasets have been created.
The plot below shows these datasets.
Blue values in all plots are identical, the red ones were the imputed ones.
The imputed points visibly resemble the distribution of the real points.

```{r}
xyplot(imp, Age ~ lFare | .imp)
```

The idea of the package is to continue fitting the model on all 5 
datasets and then pooling the results back together.
I will only use the imputed values of 1 dataset though.

```{r}
impAge <- complete(imp)$Age
```












***










# Modeling

In this section I will create the input matrix ($X$) and fit different models
to it.
To estimate the prediction error of these models I will use cross validation.
The best Model will ultimately be chosen for the prediction.



## Create Input Matrix

First, I need to create the input matrix.
I will call it $X$ as in $Y = f(X) + \epsilon$, where $f$ is the model
$\epsilon$ is the bayes rate, $X$ is the input and $Y$ the output
matrix.
The input matrix has the form $N \times p$ with $N$ rows (the observations)
and $p$ columns (the features or predictor variables).
$Y$ is a class indicator matrix of $N \times 1$ where $0$ indicates 
*non-survivor* and $1$ indicates *survivor*

In the previous section I carelessly created new features.
The assumptions that I made were based on complete data.
Then, I used imputation to replace missing values.
Now, I have to do the feature extraction again in a proper way.
It should include imputed data and it should be aplicable on the test and 
train set.
I will write a function for this.
The function should take the datasets and return a ready-to-use numeric 
input matrix.
For categorical features I have to create dummy variables.

```{r}
MakeX <- function(train, test, 
                  naFare = 80, naEmbarked = "S", naAge = impAge) {
  # combine datasets
  keepCols <- c("PassengerId", "Pclass", "Name", "Sex", "Age", "SibSp", 
                "Parch", "Ticket", "Fare", "Cabin", "Embarked")
  train <- train[, keepCols, with = FALSE]
  test <- test[, keepCols, with = FALSE]
  full <- rbind(train, test)
  
  # impute missing values
  full[is.na(Fare), Fare := naFare]
  full[Embarked == "", Embarked := naEmbarked]
  full[, Age := impAge]
  
  # extract features from Names
  titles <- gsub('(.*, )|(\\..*)', '', full$Name)
  surnames <- vapply(
    full$Name, 
    function(x) strsplit(x, "[,. ]")[[1]][1],
    character(1)
  )
  full$isMaster <- titles == "Master"
  counts <- table(surnames)
  full$SNCount <- vapply(
    surnames, 
    function(sn) counts[names(counts) == sn],
    integer(1)
  )
  
  # extract features from Age
  full$isU14 <- full$Age < 14
  
  # dummy for sex
  full$isMale <- full$Sex == "male"
  
  # extract Family features
  full$FMembers <- full$SibSp + full$Parch + 1
  full$SibSpIs1 <- full$SibSp == 1
  full$ParchIs1 <- full$Parch == 1
  full$smallFamily <- full$FMembers > 1 & full$FMembers < 5
  full$SNCountIs2 <- full$SNCount == 2
  
  # transform Fare
  full$lFare <- log10(full$Fare + 1)
  
  # extract Ticket feature
  txt <- toupper(gsub("[0-9\\. /]", "", full$Ticket))
  full$isPC <- txt %in% c("PC", "PPP", "PP")
  
  # extract Cabin features
  full$Deck <- vapply(
    full$Cabin, 
    function(x) strsplit(x, "")[[1]][1],
    character(1)
  )
  full[is.na(Deck), Deck := ""]
  full$noDeck <- full$Deck == ""
  full$nCabins <- vapply(
    full$Cabin, 
    function(x) length(strsplit(x, " ")[[1]]),
    integer(1)
  )
  full$hasCabin <- full$nCabins > 0
  
  # extract Embarked features
  full$fromC <- full$Embarked == "C"
  full$fromQ <- full$Embarked == "Q"
  
  # make X
  keepCols <- c("Pclass", "isMale", "Age", "isU14", "SibSp", "SibSpIs1",
                "Parch", "ParchIs1", "FMembers", "smallFamily", "SNCount",
                "SNCountIs2", "isPC", "Fare", "lFare", "nCabins", "hasCabin",
                "noDeck", "fromC", "fromQ")
  l <- lapply(keepCols, function(colName) { as.integer(full[[colName]]) })
  X <- do.call(cbind, l)
  rownames(X) <- full$PassengerId
  colnames(X) <- keepCols
  
  return(X)
}
```

With this I create X and split it into test and training again.

```{r}
X <- MakeX(train, test)
Xtrain <- X[1:nrow(train), ]
Xtest <- X[-(1:nrow(train)), ]
Ytrain <- as.integer(as.character(train$Survived))
```

## LDA

A linear discriminant analysis wants to see the data points of each class
as a multivariate Gauss cloud.
It wants to maximize the distances between the clouds' centroids 
with respect to their spreads.
In a regular LDA it is assumed that the covariance matrices of all classes
are the same.
So, for estimating the covariance matrix, all data points are pooled.
With this assumption separating hyperplanes between classes are always linear.

To get an idea what the LDA *sees* we can plot the class distributions along the
1st discriminant coordinate.
For 2 classes this is orthogonal of the separating hyperplane.
As you can see below, there is a big overlap.
We can exppect a high error rate.

```{r}
fit <- lda(Xtrain, Ytrain)
plot(fit)
```

The warning about colinear variables was something I mentioned during data
preparation.
A variable that is colinear to another variable does not bring a lot of new 
information.
But it brings a lot of variance because its coefficient estimates are unstable.
That's why it makes sense to kick out some variables --
introducing bias and reducing variance.

The function below does a forward feature selection.
A model is built stepwise by starting at only an intercept and successivly 
adding a variable.
Variable selection is done by minimizing the error rate, which is in turn
estimated by 10-fold cross validation.
This method is nested and greedy.
I set `improvement = -1` so it will not stop until it included all variables.

```{r, results='hide', message=FALSE, warning=FALSE}
stepsLDA <- stepclass(Xtrain, grouping = Ytrain, 
                   improvement = -1, method = "lda", direction = "forward")
plot(1 - stepsLDA$process$result.pm, type = "b", pch = 20,
     ylab = "error rate", main = "LDA")
```

According to this method there are at least 5 features which I should include 
and at least 5 features which I should not include.
The feature combination with the lowest error rate is...

```{r}
idx <- which.max(stepsLDA$process$result.pm)
(featsLDA <- as.character(stepsLDA$process$varname[1:idx]))
```

## QDA

The assumption that classes share the same covariance matrix is sometimes
too strict.
If we estimate a covariance matrix for each class, we get a quadratic 
separating hyperplane -- a QDA.
Now more parameters have to be estimated.

I will do a forward selection again, but this time I set `improvement = 0` to
stop as soon as the error rate goes up again.

```{r, results='hide', message=FALSE, warning=FALSE}
stepsQDA <- stepclass(Xtrain, grouping = Ytrain, 
                   improvement = 0, method = "qda", direction = "forward")
plot(1 - stepsQDA$process$result.pm, type = "b", pch = 20,
     ylab = "error rate", main = "RDA")
idx <- which.max(stepsQDA$process$result.pm)
(featsQDA <- as.character(stepsQDA$process$varname[1:idx]))
```

## RDA

There is a middle ground between QDA and LDA which is a regularized discriminant
analysis.
Here you have 2 slide controls.
One parameter adjusts how much of a shared and how much of separate covariance
matrices are used.
Another parameter adjusts to what degree the whole covariance matrix or just
its diagonal is used.
This method should be more robust to colinearity.

To estimate the best parameter combination RDA also uses cross validation.
Here, I set `fold = 3` to make the whole process a bit faster.

```{r, results='hide', message=FALSE, warning=FALSE}
stepsRDA <- stepclass(Xtrain, grouping = Ytrain, 
                   improvement = 0, method = "rda", direction = "forward",
                   fold = 3)
plot(1 - stepsRDA$process$result.pm, type = "b", pch = 20,
     ylab = "error rate", main = "SDA")
idx <- which.max(stepsRDA$process$result.pm)
(featsRDA <- as.character(stepsRDA$process$varname[1:idx]))
```


## SDA

The last one is a bit more fancy.
It is called shrinkage discriminant analysis.
This is also a regularized linear discriminant analysis but the regularization
method uses several James-Stein type estimators.
This method was actually designed for high dimensionality problems, when
you have $p \gg N$.
It also has a feature ranking functionality but I won't use that here.

```{r, results='hide', message=FALSE, warning=FALSE}
stepsSDA <- stepclass(Xtrain, grouping = Ytrain,
                      improvement = 0, method = "sda", direction = "forward",
                      verbose = FALSE)
plot(1 - stepsSDA$process$result.pm, type = "b", pch = 20,
     ylab = "error rate", main = "SDA")
idx <- which.max(stepsSDA$process$result.pm)
(featsSDA <- as.character(stepsSDA$process$varname[1:idx]))
```



## Evaluation

```{r}
CV <- list()
```

I will do a final cross validation to estimate the Accuracy of each model
and its standard error.
I will use the `crossval` function for this.
It takes care of keeping class proportions when splitting data.
By default this repeats a 10-fold cross validation 20 times.

```{r}
# LDA
predLDA <- function(trainX, trainY, testX, testY) {
  fit <- lda(trainX, grouping = trainY)
  pred <- predict(fit, newdata = testX)$class
  acc <- sum(pred == testY) / length(pred)
  return(acc)
}
X <- Xtrain[, colnames(Xtrain) %in% featsLDA[-1]]
CV$LDA <- crossval(predLDA, X, Ytrain, verbose = FALSE)

# QDA
predQDA <- function(trainX, trainY, testX, testY) {
  fit <- qda(trainX, grouping = trainY)
  pred <- predict(fit, newdata = testX)$class
  acc <- sum(pred == testY) / length(pred)
  return(acc)
}
X <- Xtrain[, colnames(Xtrain) %in% featsQDA[-1]]
CV$QDA <- crossval(predQDA, X, Ytrain, verbose = FALSE)
```

I will reduce the folds and number of repeats for the RDA because it
would take to long otherwise (it also uses a cross validation in the
fitting process).

```{r}
# RDA
predRDA <- function(trainX, trainY, testX, testY) {
  fit <- rda(trainX, grouping = trainY, fold = 3)
  pred <- predict(fit, newdata = testX)$class
  acc <- sum(pred == testY) / length(pred)
  return(acc)
}
X <- Xtrain[, colnames(Xtrain) %in% featsRDA[-1]]
CV$RDA <- crossval(predRDA, X, Ytrain, verbose = FALSE, K = 5, B = 10)

# SDA
predSDA <- function(trainX, trainY, testX, testY) {
  fit <- sda(trainX, L = trainY, verbose = FALSE)
  pred <- predict(fit, Xtest = testX, verbose = FALSE)$class
  acc <- sum(pred == testY) / length(pred)
  return(acc)
}
X <- Xtrain[, colnames(Xtrain) %in% featsSDA[-1]]
CV$SDA <- crossval(predSDA, X, Ytrain, verbose = FALSE)
```

The plot below summarizes the results.
*QDA* wins with more than 82% predicted accuracy.
This model will be chosen for the final prediction.

```{r}
l <- lapply(CV, function(i) { data.frame(Acc = i$stat, se = i$stat.se) })
res <- do.call(rbind, l)
res$Model <- rownames(res)
ggplot(res, aes(x = Model, y = Acc)) +
  geom_point() +
  geom_errorbar(aes(ymax = Acc + se, ymin = Acc - se)) +
  coord_flip() +
  theme_classic()
```



